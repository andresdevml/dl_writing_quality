{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoqF/B3x33Ko+NVQmoXnwg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresdevml/dl_writing_quality/blob/main/data_scaler_padding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importamos librerias de interes**"
      ],
      "metadata": {
        "id": "kEP07UHPFVPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.layers import RepeatVector\n",
        "\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy import interpolate\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import pickle"
      ],
      "metadata": {
        "id": "JP_K7k0-FaYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importamos la data**"
      ],
      "metadata": {
        "id": "2u4_thR-GXPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conectamos al drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definimos el directorio\n",
        "dir_data_kaggle='./drive/MyDrive/lwpwq/data'\n",
        "\n",
        "# extraemos la data\n",
        "\n",
        "# open a file, where you stored the pickled data\n",
        "file = open(dir_data_kaggle+'/train_data.pkl', 'rb')\n",
        "\n",
        "# dump information to that file\n",
        "train_data = pickle.load(file)\n",
        "\n",
        "# close the file\n",
        "file.close()\n",
        "\n",
        "df_train_logs=pd.read_csv(filepath_or_buffer=dir_data_kaggle+'/train_logs.csv')\n",
        "\n",
        "df_train_scores=pd.read_csv(filepath_or_buffer=dir_data_kaggle+'/train_scores.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJkTy6vsGbKn",
        "outputId": "4caccfac-de48-4195-81ee-6a7c3f41b1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vamos a probar el codigo con 5 ids nada mas\n",
        "\n",
        "\n",
        "id_list_test=list(train_data.keys())[:5]\n",
        "\n",
        "\n",
        "train_data={key:train_data[key] for key in id_list_test}"
      ],
      "metadata": {
        "id": "5C4FgKs7yH0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Escalamos la data**"
      ],
      "metadata": {
        "id": "hBVVAlflfU4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sabemos que dyn data tiene 8 columnas\n",
        "\n",
        "# ajustamos y guardamos los scalers\n",
        "\n",
        "list_scaler=[]\n",
        "\n",
        "for k in range(8):\n",
        "\n",
        "  list_seq=[]\n",
        "  for id in train_data:\n",
        "    seq=list(train_data[id]['dyn_data'][:,k])\n",
        "    list_seq=list_seq+seq\n",
        "\n",
        "  list_scaler.append(\n",
        "                      MinMaxScaler(feature_range=(0, 5))\n",
        "                      .fit(\n",
        "                               np.array(list_seq).reshape(-1,1)\n",
        "                                                                  )\n",
        "                                                                               )"
      ],
      "metadata": {
        "id": "6mZk77qEfYJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aplicamos el escaler para cada secuencia en cada columnsa de dyn data\n",
        "\n",
        "for id in train_data:\n",
        "\n",
        "  dyn_data=train_data[id]['dyn_data']\n",
        "\n",
        "  train_data[id]['dyn_data']=np.hstack(tup=tuple(\n",
        "\n",
        "                  [ list_scaler[k].transform(dyn_data[:,k].reshape(-1,1)) for k in range(8) ]\n",
        "\n",
        "                                              )\n",
        "                                                  )"
      ],
      "metadata": {
        "id": "zz6Nm0Vm-fTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Aplicamos Padding sobre la data**"
      ],
      "metadata": {
        "id": "g0ZWHvj8L0LK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# determianmos la longitud maxima de las secuencias\n",
        "\n",
        "max_len=int(df_train_logs['event_id'].max()*1.20)\n",
        "\n",
        "print(max_len)\n"
      ],
      "metadata": {
        "id": "ZVbj7sp8L33w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76b71d0-566e-46dc-c0ce-861b039212f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generamos la lista para cada columna\n",
        "\n",
        "list_data=[]\n",
        "\n",
        "for column in range(8):\n",
        "\n",
        "  list_seq=[]\n",
        "\n",
        "  for id in train_data:\n",
        "    list_seq.append(train_data[id]['dyn_data'][:,column])\n",
        "\n",
        "  list_data.append(list_seq)"
      ],
      "metadata": {
        "id": "TYCO2VYUTC6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aplicamos padding a cada columna y juntamos las columns\n",
        "pad_list_data=[tf.keras.utils.pad_sequences(\n",
        "                                            sequences=column,\n",
        "                                              maxlen=max_len,\n",
        "                                              dtype='float64',\n",
        "                                              padding='post',\n",
        "                                              truncating='pre',\n",
        "                                              value=-1\n",
        "\n",
        "                                                    ) for column in list_data\n",
        "                                                              ]\n",
        "\n",
        "\n",
        "pad_train_data=np.hstack(tup=tuple(pad_list_data)).reshape(len(train_data),-1,8)"
      ],
      "metadata": {
        "id": "30L8-dKAqCcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exportamos la data**"
      ],
      "metadata": {
        "id": "sK6I4m9guepi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JotHMbcWz10I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}